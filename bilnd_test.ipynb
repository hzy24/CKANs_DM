{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.CKANs import *\n",
    "from src.utils import *\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage you can choose CKANs / CKANs_InceptionBig / CKANs_BigConvs\n",
    "model = CKANs(input_channels=1, num_classes=3, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('binned_data_20.pkl', 'rb') as f:\n",
    "    all_data_params, all_images = pkl.load(f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test SIDM0.3\n",
    "\n",
    "labels = np.zeros(18000)\n",
    "labels[:10800] = 0\n",
    "labels[10800:14400] = 1\n",
    "labels[14400:] = 2\n",
    "\n",
    "\n",
    "# 0:3600___CDM_low+baryons 3600:7200___CDM_hi+baryons 7200:10800___CDM+baryons \n",
    "# 10800:14400___SIDM0.1 14400:18000___SIDM0.3 18000:21600___SIDM1.0\n",
    "selected_images = np.concatenate((all_images[:10800], all_images[10800:14400], all_images[18000:21600]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test CDM_hi\n",
    "\n",
    "# labels = np.zeros(14400)\n",
    "# labels[:7200] = 0\n",
    "# labels[7200:10800] = 1\n",
    "# labels[10800:] = 2\n",
    "\n",
    "# # 0:3600___CDM_low+baryons 3600:7200___CDM_hi+baryons 7200:10800___CDM+baryons \n",
    "# # 10800:14400___SIDM0.1 14400:18000___SIDM0.3 18000:21600___SIDM1.0\n",
    "# selected_images = np.concatenate((all_images[:3600],all_images[7200:10800],all_images[10800:14400], all_images[18000:21600]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_val, y_train, y_val = process_data(selected_images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, val_loader, device='cpu'):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.device = device\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.model.to(device)\n",
    "\n",
    "    def train(self, num_epochs=10):\n",
    "        best_model_wts = copy.deepcopy(self.model.state_dict())\n",
    "        best_acc = 0.0\n",
    "        for epoch in range(num_epochs):\n",
    "            running_loss = 0.0\n",
    "            for images, labels in tqdm(self.train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(images)\n",
    "                loss = self.loss_fn(outputs, labels.long())\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "            epoch_loss = running_loss / len(self.train_loader.dataset)\n",
    "            val_acc = compute_accuracy(self.model, self.val_loader, self.device)\n",
    "            print(f'Loss: {epoch_loss:.4f} | Val Accuracy: {val_acc:.4f}')\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                best_model_wts = copy.deepcopy(self.model.state_dict())\n",
    "        self.model.load_state_dict(best_model_wts)\n",
    "        print('Training complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 设置绘图样式和参数\n",
    "# plt.style.use([\"science\", \"grid\"])\n",
    "model_name = \"CAKNs\"\n",
    "epochs = 3\n",
    "monte_carlo = 15\n",
    "simulationNames = ['CDM', 'SIDM0.1', 'SIDM1']\n",
    "nDM_Models = len(simulationNames)\n",
    "monte_carlo_tests = []\n",
    "monte_carlo_histories = []\n",
    "all_probs = []\n",
    "prob_sidm0_3 = []\n",
    "\n",
    "\n",
    "for i in tqdm(range(monte_carlo)):\n",
    "\n",
    "    set_seed(i)\n",
    "\n",
    "    train_loader, val_loader = getGenerators(X_train, X_val, y_train, y_val)\n",
    "    \n",
    "\n",
    "    trainer = Trainer(model, train_loader, val_loader, device=device)\n",
    "    trainer.train(num_epochs=epochs)\n",
    "    \n",
    "\n",
    "    monte_carlo_tests.append(val_loader)\n",
    "    monte_carlo_histories.append({'epochs': epochs})\n",
    "    \n",
    "    iDM_model_probs = []\n",
    "\n",
    "    for iDM_model in range(nDM_Models):\n",
    "        this_dm_model_test_feat = X_val[y_val == iDM_model]\n",
    "        this_dm_model_test_feat = torch.tensor(this_dm_model_test_feat, dtype=torch.float32).to(device)\n",
    "        this_dm_model_test_feat = this_dm_model_test_feat.permute(0, 3, 1, 2)  \n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(this_dm_model_test_feat)\n",
    "            iDM_model_probs.append(output.cpu().numpy())\n",
    "    all_probs.append(iDM_model_probs)\n",
    "\n",
    "\n",
    "    SIDM0_3_images = all_images[14400:18000]\n",
    "    SIDM0_3_images_transformed = []\n",
    "    for img in SIDM0_3_images:\n",
    "        img_transformed = transform_resize(img)\n",
    "        SIDM0_3_images_transformed.append(img_transformed)\n",
    "    SIDM0_3_images_transformed = torch.stack(SIDM0_3_images_transformed).to(device)\n",
    "    \n",
    "    batch_size = 32\n",
    "    SIDM0_3_probs = []\n",
    "    for i in range(0, len(SIDM0_3_images_transformed), batch_size):\n",
    "        batch = SIDM0_3_images_transformed[i:i+batch_size]\n",
    "        with torch.no_grad():\n",
    "            output = model(batch)\n",
    "\n",
    "            SIDM0_3_probs.append(output.cpu().numpy())\n",
    "\n",
    "    prob_sidm0_3.append(np.concatenate(SIDM0_3_probs, axis=0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_probs_nested = [[np.array(prob) for prob in probs] for probs in all_probs]\n",
    "prob_sidm0_3 = np.array(prob_sidm0_3)\n",
    "\n",
    "\n",
    "with open(\"final_model_%s.pkl\" % model_name, \"wb\") as f:\n",
    "    pkl.dump([all_probs_nested, prob_sidm0_3, monte_carlo_histories], f)\n",
    "\n",
    "# 保存最终结果\n",
    "pkl.dump([all_probs, prob_sidm0_3, monte_carlo_histories], open(\"final_model_%s.pkl\" % model_name, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "gs = GridSpec(20, 1)\n",
    "\n",
    "ax = plt.subplot(gs[:14, 0])\n",
    "c = ['r', 'b', 'g', 'c']\n",
    "stds = []\n",
    "cross_sections = np.array([0., 0.1, 1.0])\n",
    "\n",
    "for iTelescope, n_samples_per_subset in enumerate([10, 100, 1000]):\n",
    "    these_probs = np.exp(prob_sidm0_3)\n",
    "    these_probs = these_probs / np.sum(these_probs, axis=-1, keepdims=True)\n",
    "    prediction, err = get_predictions_per_subset(these_probs, n_samples_per_subset, cross_sections=cross_sections)\n",
    "    mean = np.nanmedian(prediction)\n",
    "    std = np.nanmean(err)\n",
    "    stds.append(std)\n",
    "    x = np.linspace(0., 0.7, 1000)\n",
    "    pdf = norm.pdf(x, mean, std)\n",
    "    \n",
    "    pdf_sum = np.sum(pdf) * (x[1] - x[0])\n",
    "\n",
    "    if pdf_sum != 0:\n",
    "        pdf /= pdf_sum\n",
    "    else:\n",
    "        pdf = np.ones_like(pdf) / len(pdf)\n",
    "        pdf /= np.sum(pdf) * (x[1] - x[0])\n",
    "    \n",
    "    ax.plot(x, pdf, color=c[iTelescope])\n",
    "    if iTelescope == 0:\n",
    "        ylims = ax.get_ylim()\n",
    "    ax.fill_between(x[(x > mean - std) & (x < mean + std)], \n",
    "                    np.zeros(len(x[(x > mean - std) & (x < mean + std)])),\n",
    "                    pdf[(x > mean - std) & (x < mean + std)], color=c[iTelescope], alpha=0.1)\n",
    "    ax.plot([mean - std, mean - std], [0, norm.pdf(mean - std, mean, std)], '-', color=c[iTelescope], label='Sample Size: %i' % n_samples_per_subset)\n",
    "    ax.plot([mean + std, mean + std], [0, norm.pdf(mean + std, mean, std)], '-', color=c[iTelescope])\n",
    "\n",
    "subsets = np.logspace(1, 2.5, 20)\n",
    "stds = [np.nanmean(get_predictions_per_subset(these_probs, int(i), cross_sections=cross_sections)[1]) for i in subsets]\n",
    "ax1 = plt.subplot(gs[16:, 0])\n",
    "ax1.set_yscale('log')\n",
    "ax1.plot(subsets, stds)\n",
    "ax1.set_xlabel('Sample Size', fontsize=12)\n",
    "ax1.set_ylabel('Error in $\\sigma_{\\\\rm DM}$', fontsize=12)\n",
    "ax1.set_xscale('log')\n",
    "\n",
    "# 确保 y 轴限制设置合理\n",
    "ax.set_ylim(0, max(ylims[1], max([np.max(norm.pdf(x, np.nanmedian(prediction), np.nanmean(err))) for prediction, err in zip(prediction, err)])))\n",
    "ax.set_xlim(0.1, 0.7)\n",
    "ax.legend(loc=1)\n",
    "ax.set_xlabel(r'$\\sigma_{\\rm DM}/m$ [cm$^2$/g]', fontsize=12)\n",
    "ax.set_ylabel(r'$p(\\sigma_{\\rm DM}/m)$', fontsize=12)\n",
    "\n",
    "filename = \"sidm_0p3_blind_test.pdf\"\n",
    "plt.savefig(filename)\n",
    "\n",
    "plt.show()\n",
    "os.system(\"pdfcrop %s %s\" % (filename, filename))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pulsar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
