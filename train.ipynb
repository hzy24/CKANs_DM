{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.CKANs import *\n",
    "from src.utils import *\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage you can choose CKANs / CKANs_InceptionBig / CKANs_BigConvs\n",
    "model = CKANs(input_channels=1, num_classes=3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 10743\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images shape: torch.Size([32, 3, 100, 100])\n",
      "\n",
      "labels shape: torch.Size([32])\n",
      "\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('/home/frb/0hzy/DM/binned_data_20.pkl', 'rb') as f:\n",
    "    all_data_params, all_images = pkl.load(f)\n",
    "\n",
    "\n",
    "labels = np.zeros(18000)\n",
    "labels[:10800] = 0\n",
    "labels[10800:14400] = 1\n",
    "labels[14400:] = 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 0:3600___CDM_low+baryons 3600:7200___CDM_hi+baryons 7200:10800___CDM+baryons \n",
    "# 10800:14400___SIDM0.1 14400:18000___SIDM0.3 18000:21600___SIDM1.0\n",
    "selected_images = np.concatenate((all_images[:10800], all_images[10800:14400], all_images[18000:21600]))\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = process_data(selected_images, labels)\n",
    "\n",
    "augmentation_factor = 1  # You can use it to multiply your data, we did not do that\n",
    "train_dataset = CustomDataset(X_train, y_train, transform=transform_resize, augmentation_factor=augmentation_factor)\n",
    "val_dataset = CustomDataset(X_val, y_val, transform=transform_resize, augmentation_factor=augmentation_factor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# check the shape\n",
    "for images, labels in train_loader:\n",
    "    print(f\"images shape: {images.shape}\\n\")\n",
    "    print(f\"labels shape: {labels.shape}\\n\")\n",
    "\n",
    "    break\n",
    "\n",
    "\n",
    "print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "class Trainer:\n",
    "    def __init__(self, model, device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.val_accuracies = []\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_model_wts = None\n",
    "        self.checkpoint_path = 'your_checkpoint_path'\n",
    "\n",
    "        # Load existing model parameters if available\n",
    "        if os.path.exists(self.checkpoint_path):\n",
    "            self.model.load_state_dict(torch.load(self.checkpoint_path))\n",
    "            print(\"Loaded existing model parameters.\")\n",
    "\n",
    "    def train(self, train_loader, val_loader, epochs=100):\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            for epoch in range(epochs):\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                # Initialize inner progress bar\n",
    "                batch_progress_bar = tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "                for images, labels in train_loader:\n",
    "                    images, labels = images.to(self.device), labels.to(self.device)                   \n",
    "                    self.optimizer.zero_grad()\n",
    "                    outputs = self.model(images)\n",
    "                    loss = self.criterion(outputs, labels.long())\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item() * images.size(0)\n",
    "                    running_corrects += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "                    # Update inner progress bar\n",
    "                    batch_progress_bar.update(1)\n",
    "                batch_progress_bar.close()\n",
    "                epoch_loss = running_loss / len(train_loader.dataset)\n",
    "                epoch_acc = running_corrects / len(train_loader.dataset)\n",
    "                self.train_losses.append(epoch_loss)\n",
    "                self.train_accuracies.append(epoch_acc)\n",
    "\n",
    "                val_loss, val_acc = self.validate(val_loader)\n",
    "                self.val_losses.append(val_loss)\n",
    "                self.val_accuracies.append(val_acc)\n",
    "\n",
    "                # Save the best model\n",
    "                if val_loss < self.best_val_loss:\n",
    "                    self.best_val_loss = val_loss\n",
    "                    self.best_model_wts = self.model.state_dict()\n",
    "                    torch.save(self.best_model_wts, self.checkpoint_path)\n",
    "\n",
    "                if epoch % 1 == 0:\n",
    "                    print(f'Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    " \n",
    "            self.plot_metrics()\n",
    "            # self.save_metrics()\n",
    "\n",
    "            # Load best model weights\n",
    "            self.model.load_state_dict(self.best_model_wts)\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print('Training interrupted.')\n",
    "\n",
    "        finally:\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            print(f'Training finished in {elapsed_time // 60:.0f}m {elapsed_time % 60:.0f}s.')\n",
    "\n",
    "    def validate(self, val_loader):\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels.long())\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = correct / total\n",
    "        return val_loss, val_acc\n",
    "\n",
    "    def plot_metrics(self):\n",
    "        epochs = range(1, len(self.train_losses) + 1)\n",
    "\n",
    "        plt.figure(figsize=(14, 5))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs, self.train_losses, label='Train Loss')\n",
    "        plt.plot(epochs, self.val_losses, label='Validation Loss')\n",
    "        plt.title('Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs, self.train_accuracies, label='Train Accuracy')\n",
    "        plt.plot(epochs, self.val_accuracies, label='Validation Accuracy')\n",
    "        plt.title('Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('your_plot_path')\n",
    "\n",
    "    # def save_metrics(self):\n",
    "    #     with open('metrics.txt', 'w') as f:\n",
    "    #         f.write('Train Losses: ' + ','.join(map(str, self.train_losses)) + '\\n')\n",
    "    #         f.write('Validation Losses: ' + ','.join(map(str, self.val_losses)) + '\\n')\n",
    "    #         f.write('Train Accuracies: ' + ','.join(map(str, self.train_accuracies)) + '\\n')\n",
    "    #         f.write('Validation Accuracies: ' + ','.join(map(str, self.val_accuracies)) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Go KANs!!!\")\n",
    "\n",
    "trainer = Trainer(model, device)\n",
    "\n",
    "trainer.train(train_loader, val_loader, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_list = {\n",
    "#     # poly\n",
    "#     # 'poly_0': lambda c0 : c0,\n",
    "#     'poly_1': lambda x, c0, c1: c0 + c1*x,\n",
    "#     'poly_2': lambda x, c0, c1, c2: c0 + c1*x + c2*x**2,\n",
    "#     'poly_3': lambda x, c0, c1, c2, c3: c0 + c1*x + c2*x**2 + c3*x**3,\n",
    "#     'poly_4': lambda x, c0, c1, c2, c3, c4: c0 + c1*x + c2*x**2 + c3*x**3 + c4*x**4,\n",
    "#     '1/x': lambda x, c0, c1: c0/(x+c1),\n",
    "#     '1/x^2': lambda x, c0, c1: c0/(x+c1)**2,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv1[1].conv3[1].convs[0].conv.save_yi()\n",
    "expr, r2 = model.conv1[1].conv3[1].convs[0].conv.fit_symbolic_for_each_feature()\n",
    "\n",
    "# expr, r2 = model.conv1[1].conv3[1].convs[0].conv.fit_symbolic_for_each_feature(fit_lib=fit_list)  # use your own fit_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pulsar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
