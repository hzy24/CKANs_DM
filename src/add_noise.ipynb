{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from lenspack.image.inversion import ks93, ks93inv\n",
    "from lenspack.utils import sigma_critical\n",
    "import numpy as np\n",
    "from astropy import cosmology\n",
    "from astropy.units.core import Unit\n",
    "\n",
    "from copy import deepcopy as cp\n",
    "from numpy.random import poisson\n",
    "\n",
    "from scipy.interpolate import interp2d\n",
    "\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "def weak_lensing( images, params, zl=0.3, zs=2.0, \\\n",
    "                 ngal_per_sq_arcmin=100., \\\n",
    "                 kpc_per_pixel=20., ell_disp=0.3, \n",
    "                 gals_per_bin=2., interpolate=False, **kwargs ):\n",
    "    '''\n",
    "    add weak lensing noise \n",
    "    '''\n",
    "    \n",
    "    kwargs = kwargs['kwargs']\n",
    "    print(kwargs)\n",
    "\n",
    "    if 'zl' in kwargs.keys():\n",
    "        zl = kwargs['zl']\n",
    "    if 'zs' in kwargs.keys():\n",
    "        zs = kwargs['zs']\n",
    "    if 'ngal_per_sq_arcmin' in kwargs.keys():\n",
    "        ngal_per_sq_arcmin = kwargs['ngal_per_sq_arcmin']\n",
    "    if 'kpc_per_pixel' in kwargs.keys():\n",
    "        kpc_per_pixel = kwargs['kpc_per_pixel']\n",
    "    if 'ell_disp' in kwargs.keys():\n",
    "        ell_disp = kwargs['ell_disp']\n",
    "    if 'e1_bias' in kwargs.keys():\n",
    "        e1_bias = kwargs['e1_bias']     \n",
    "    if 'e2_bias' in kwargs.keys():\n",
    "        e2_bias = kwargs['e2_bias']  \n",
    "    if 'interpolate' in kwargs.keys():\n",
    "        interpolate = kwargs['interpolate']\n",
    "        \n",
    "    ngal_per_sq_arcmin  /= Unit('arcminute')**2\n",
    "    \n",
    "    kpc_per_pixel *= Unit('kpc')\n",
    "    \n",
    "    kpc_per_arcmin = \\\n",
    "        1*Unit(\"arcminute\").to(\"radian\")*cosmology.Planck18.angular_diameter_distance(0.3).to(\"kpc\")/Unit(\"arcminute\")\n",
    "\n",
    "    arcmin_per_pixel = kpc_per_pixel / kpc_per_arcmin \n",
    "    \n",
    "    sq_arcmin_per_pixel = arcmin_per_pixel * arcmin_per_pixel  \n",
    "    \n",
    "    ngalaxies_per_pixel =  ngal_per_sq_arcmin * sq_arcmin_per_pixel\n",
    "    \n",
    "    sigma_crit = sigma_critical(zl, zs, cosmology.Planck18)\n",
    "    \n",
    "    peak = params['lensing_norm']*Unit(\"solMass\")/(Unit(\"Mpc\")*Unit(\"Mpc\"))\n",
    "   \n",
    "    peak_pc_sq = peak.to(Unit(\"solMass\")/(Unit(\"pc\")*Unit(\"pc\")))/sigma_crit\n",
    "    rebin_pix = int(np.ceil(gals_per_bin/ngalaxies_per_pixel))\n",
    "\n",
    "    rebin_pix = [ i for i in range(1,rebin_pix+1) if images[0].shape[0]//i == images[0].shape[0]/i ][-1]\n",
    "    \n",
    "    all_wl_images = []\n",
    "    for idx, image in enumerate(images):\n",
    "        convergence = image*peak_pc_sq[idx]\n",
    "        # print(f\"convergence shape: {convergence.shape}\")\n",
    "        ampl = np.mean(convergence)\n",
    "\n",
    "        e1,e2 = ks93inv(convergence,convergence*0.)\n",
    "        \n",
    "\n",
    "\n",
    "        e1 += np.random.randn( e1.shape[0],e1.shape[0] )*ell_disp/np.sqrt(2.)/np.sqrt(ngalaxies_per_pixel)\n",
    "        e2 += np.random.randn( e2.shape[0],e2.shape[0] )*ell_disp/np.sqrt(2.)/np.sqrt(ngalaxies_per_pixel) \n",
    "    \n",
    "        e1 = e1_bias[0] + (1.+e1_bias[1])*e1\n",
    "        e2 = e2_bias[0] + (1.+e2_bias[1])*e2\n",
    "\n",
    "        \n",
    "        kappaE, kappB = ks93(e1,e2)\n",
    "        \n",
    "        #renormliase back to 0->1\n",
    "        kappaE -= np.min(kappaE)\n",
    "        kappaE += ampl\n",
    "        kappaE /= np.max(kappaE)\n",
    "        \n",
    "        if interpolate & (rebin_pix > 1):\n",
    "            kappaE = rebin_wl(kappaE, rebin_pix)\n",
    "        \n",
    "        all_wl_images.append(kappaE)\n",
    "        \n",
    "    return np.array(all_wl_images)\n",
    "\n",
    "def rebin_wl( kappaE, rebin_pix):\n",
    "    \n",
    "    new_shape = kappaE.shape[0]//rebin_pix\n",
    "    \n",
    "    new_image = rebin( kappaE, (new_shape,new_shape))\n",
    "    \n",
    "    z = zoom( new_image, rebin_pix)\n",
    "    \n",
    "    return z\n",
    "\n",
    "def xray( xray_emission_dimensionless, params, exposure_time=10_000, kpc_per_pixel=20, **kwargs ):\n",
    "\n",
    "    if isinstance(xray_emission_dimensionless, list):\n",
    "        xray_emission_dimensionless = np.array(xray_emission_dimensionless)\n",
    "    \n",
    "    if 'xray_norm' in params:\n",
    "        params['xray_norm'] = np.array(params['xray_norm'])\n",
    "\n",
    "    kwargs = kwargs['kwargs']\n",
    "    print(kwargs)\n",
    "    xray_norm = params['xray_norm']\n",
    "    \n",
    "    if 'exposure_time' in kwargs.keys():\n",
    "        exposure_time = kwargs['exposure_time']\n",
    "    if 'kpc_per_pixel' in kwargs.keys():\n",
    "        kpc_per_pixel = kwargs['kpc_per_pixel']\n",
    "    if 'zl' in kwargs.keys():\n",
    "        zl = kwargs['zl']      \n",
    "    xray_emission = xray_norm[:,np.newaxis,np.newaxis]* \\\n",
    "        xray_emission_dimensionless*Unit('erg') / Unit('s') / Unit('cm')**2 / Unit('arcmin')**2\n",
    "         \n",
    "    kpc_per_arcmin = \\\n",
    "        1*Unit(\"arcminute\").to(\"radian\")*cosmology.Planck18.angular_diameter_distance(zl).to(\"kpc\")/Unit(\"arcminute\")\n",
    "\n",
    "    exposure_time = exposure_time*Unit('s') # defualt 10 ks\n",
    "    \n",
    "    #the size of a pixel collecting area in arcminutes\n",
    "    fov_arcmin = (kpc_per_pixel*Unit('kpc')/kpc_per_arcmin)**2 \n",
    "    \n",
    "    #the aperture size of Chandra\n",
    "    aperture = np.pi*(60.*Unit('cm'))**2\n",
    "    \n",
    "    #Now calculate the total integrate photon count\n",
    "    xray_energy_per_pixel = xray_emission * exposure_time * fov_arcmin * aperture\n",
    "    \n",
    "    #Then convert to kev\n",
    "    total_energy_in_kev = xray_energy_per_pixel.to(\"keV\")\n",
    "    \n",
    "    \n",
    "    #Assuming a 2kev photo, calculate the number of photons\n",
    "    number_photons = total_energy_in_kev/(2.*Unit(\"keV\"))\n",
    "    \n",
    "    all_xray_images = []\n",
    "    for iImage in range(xray_emission_dimensionless.shape[0]):\n",
    "        \n",
    "        \n",
    "        image_inted = np.round(number_photons[iImage])\n",
    "        exposure = poisson( image_inted.reshape(np.prod(image_inted.shape)), \\\n",
    "                       size=np.prod(image_inted.shape) ).reshape(image_inted.shape)  \n",
    "        \n",
    "        bkgrd = poisson( np.ones(image_inted.shape).reshape(np.prod(image_inted.shape)), \\\n",
    "                       size=np.prod(image_inted.shape) ).reshape(image_inted.shape)  \n",
    "        all_image = (exposure+bkgrd).view(float)\n",
    "        \n",
    "        all_image /= np.max(all_image)\n",
    "        \n",
    "    \n",
    "        all_xray_images.append(all_image)\n",
    "        \n",
    "    return np.array(all_xray_images)\n",
    "\n",
    "    \n",
    "def add_noise_to_images( images, params, channels, noise_parameters={} ):\n",
    "    \n",
    "    print(\"Adding noise to :\", list(noise_parameters.keys()))\n",
    "    \n",
    "    default_noise_params = {}\n",
    "    default_noise_params['total'] = \\\n",
    "        {'zl':0.3, 'zs':2.0, \\\n",
    "        'ngal_per_sq_arcmin':100., \\\n",
    "        'kpc_per_pixel':20., \n",
    "         'ell_disp':0.3,\n",
    "         'e1_bias':[0.,0.], \n",
    "         'e2_bias':[0.,0.],\n",
    "        'interpolate':False}\n",
    "        \n",
    "    default_noise_params['xray'] = {\\\n",
    "            'exposure_time':10_000,\\\n",
    "            'kpc_per_pixel':20,\\\n",
    "            'zl':default_noise_params['total']['zl']}\n",
    "    \n",
    "    noisy_images = cp(images)\n",
    "    # 初始化 noisy_images 为 NumPy 数组\n",
    "    # noisy_images = np.array(cp(images))\n",
    "    \n",
    "    for noise_component in noise_parameters.keys():\n",
    "        if noise_component == 'total' :\n",
    "            for i in noise_parameters['total'].keys():\n",
    "                default_noise_params['total'][i] = noise_parameters['total'][i]\n",
    "            idx = [ i for i in range(len(channels)) if channels[i] == 'total'][0]\n",
    "            noisy_images[:,:,:,idx] = weak_lensing( images[:,:,:,idx], params, kwargs=default_noise_params['total'] )\n",
    "            \n",
    "        if noise_component == 'xray':\n",
    "            for i in noise_parameters['xray'].keys():\n",
    "                default_noise_params['xray'][i] = noise_parameters['xray'][i]\n",
    "                \n",
    "            idx = [ i for i in range(len(channels)) if channels[i] == 'xray'][0]\n",
    "            noisy_images[:,:,:,idx] = xray( images[:,:,:,idx], params, kwargs=default_noise_params['xray'] )\n",
    "    \n",
    "    \n",
    "    return noisy_images\n",
    "\n",
    "\n",
    "def get_einstein_radius( cluster_mass, zl=0.3, zs=2.0 ):\n",
    "    \n",
    "    cluster_mass  = cluster_mass*Unit('solMass')\n",
    "    sigma_crit = sigma_critical(zl, zs, cosmology.Planck18)\n",
    "\n",
    "    einstein_rad = np.sqrt( cluster_mass / sigma_crit).to(Unit('Mpc'))\n",
    "    \n",
    "    return einstein_rad\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy as cp\n",
    "\n",
    "# default params\n",
    "default_noise_params = {\n",
    "    'total': {\n",
    "        'zl': 0.3,\n",
    "        'zs': 2.0,\n",
    "        'ngal_per_sq_arcmin': 100.,\n",
    "        'kpc_per_pixel': 20.,\n",
    "        'ell_disp': 0.3,\n",
    "        'e1_bias': [0., 0.],\n",
    "        'e2_bias': [0., 0.],\n",
    "        'interpolate': False\n",
    "    },\n",
    "    'xray': {\n",
    "        'exposure_time': 10_000,\n",
    "        'kpc_per_pixel': 20,\n",
    "        'zl': 0.3\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "channels = ['total','stellar','xray']  \n",
    "\n",
    "def add_noise_to_images(images, params, channels, noise_parameters={}):\n",
    "\n",
    "    images = np.array(images)\n",
    "    noisy_images = np.array(cp(images))  \n",
    "    \n",
    "    print(f\"Images shape: {images.shape}\")\n",
    "    print(f\"Noisy images shape: {noisy_images.shape}\")\n",
    "    \n",
    "    for noise_component in noise_parameters.keys():\n",
    "        if noise_component == 'total':\n",
    "            for i in noise_parameters['total'].keys():\n",
    "                default_noise_params['total'][i] = noise_parameters['total'][i]\n",
    "            idx = [i for i in range(len(channels)) if channels[i] == 'total'][0]\n",
    "            # 调试输出\n",
    "            print(f\"Applying weak_lensing to channel index {idx}\")\n",
    "            noisy_images[:,:,:,idx] = weak_lensing(images[:,:,:,idx], params, kwargs=default_noise_params['total'])\n",
    "            \n",
    "        if noise_component == 'xray':\n",
    "            for i in noise_parameters['xray'].keys():\n",
    "                default_noise_params['xray'][i] = noise_parameters['xray'][i]\n",
    "                \n",
    "            idx = [i for i in range(len(channels)) if channels[i] == 'xray'][0]\n",
    "\n",
    "            print(f\"Applying xray to channel index {idx}\")\n",
    "            noisy_images[:,:,:,idx] = xray(images[:,:,:,idx], params, kwargs=default_noise_params['xray'])\n",
    "    \n",
    "    return noisy_images\n",
    "\n",
    "\n",
    "with open('binned_data_20.pkl', 'rb') as f:\n",
    "    all_data_params, all_images = pkl.load(f)\n",
    "\n",
    "    \n",
    "all_images = np.array(all_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (25816, 100, 100, 3)\n",
      "Noisy images shape: (25816, 100, 100, 3)\n",
      "Applying weak_lensing to channel index 0\n",
      "{'zl': 0.3, 'zs': 2.0, 'ngal_per_sq_arcmin': 100, 'kpc_per_pixel': 20.0, 'ell_disp': 0.3, 'e1_bias': [0.0, 0.0], 'e2_bias': [0.0, 0.0], 'interpolate': False}\n",
      "Applying xray to channel index 2\n",
      "{'exposure_time': 10000, 'kpc_per_pixel': 20, 'zl': 0.3}\n",
      "Images shape: (25816, 100, 100, 3)\n",
      "Noisy images shape: (25816, 100, 100, 3)\n",
      "Applying weak_lensing to channel index 0\n",
      "{'zl': 0.3, 'zs': 2.0, 'ngal_per_sq_arcmin': 50, 'kpc_per_pixel': 20.0, 'ell_disp': 0.3, 'e1_bias': [0.0, 0.0], 'e2_bias': [0.0, 0.0], 'interpolate': False}\n",
      "Applying xray to channel index 2\n",
      "{'exposure_time': 10000, 'kpc_per_pixel': 20, 'zl': 0.3}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy as cp\n",
    "\n",
    "# 默认噪声参数\n",
    "default_noise_params = {\n",
    "    'total': {\n",
    "        'zl': 0.3,\n",
    "        'zs': 2.0,\n",
    "        'ngal_per_sq_arcmin': 100.,\n",
    "        'kpc_per_pixel': 20.,\n",
    "        'ell_disp': 0.3,\n",
    "        'e1_bias': [0., 0.],\n",
    "        'e2_bias': [0., 0.],\n",
    "        'interpolate': False\n",
    "    },\n",
    "    'xray': {\n",
    "        'exposure_time': 10_000,\n",
    "        'kpc_per_pixel': 20,\n",
    "        'zl': 0.3\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "jwst_params = { \n",
    "    'total': {'ngal_per_sq_arcmin': 100}, \n",
    "    'xray': {'exposure_time': 10_000},\n",
    "    'nclusters': 8\n",
    "}\n",
    "\n",
    "euclid_params = { \n",
    "    'total': {'ngal_per_sq_arcmin': 50}, \n",
    "    'xray': {'exposure_time': 10_000},\n",
    "    'nclusters': 8\n",
    "}\n",
    "\n",
    "\n",
    "jwst_noise_params = {**default_noise_params, **jwst_params}\n",
    "noisy_images_jwst = add_noise_to_images(\n",
    "    cp(all_images),  \n",
    "    all_data_params,  \n",
    "    channels,  \n",
    "    noise_parameters=jwst_noise_params  \n",
    ")\n",
    "\n",
    "\n",
    "euclid_noise_params = {**default_noise_params, **euclid_params}\n",
    "noisy_images_euclid = add_noise_to_images(\n",
    "    cp(all_images),  \n",
    "    all_data_params,  \n",
    "    channels,  \n",
    "    noise_parameters=euclid_noise_params \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open('noisy_images_jwst.pkl', 'wb') as f:\n",
    "    pickle.dump(noisy_images_jwst, f)\n",
    "\n",
    "\n",
    "with open('noisy_images_euclid.pkl', 'wb') as f:\n",
    "    pickle.dump(noisy_images_euclid, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open('noisy_images_jwst.pkl', 'rb') as f:\n",
    "    noisy_images_jwst_loaded = pickle.load(f)\n",
    "\n",
    "\n",
    "with open('noisy_images_euclid.pkl', 'rb') as f:\n",
    "    noisy_images_euclid_loaded = pickle.load(f)\n",
    "\n",
    "# Check data\n",
    "print(\"JWST noise data shape:\", noisy_images_jwst_loaded.shape)\n",
    "print(\"Euclid noise data shape:\", noisy_images_euclid_loaded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (25816, 100, 100, 3)\n",
      "Noisy images shape: (25816, 100, 100, 3)\n",
      "Applying weak_lensing to channel index 0\n",
      "{'zl': 0.3, 'zs': 2.0, 'ngal_per_sq_arcmin': 120, 'kpc_per_pixel': 20.0, 'ell_disp': 0.3, 'e1_bias': [0.0, 0.0], 'e2_bias': [0.0, 0.0], 'interpolate': False}\n",
      "Applying xray to channel index 2\n",
      "{'exposure_time': 10000, 'kpc_per_pixel': 20, 'zl': 0.3}\n"
     ]
    }
   ],
   "source": [
    "# CSST\n",
    "csst_params = { \n",
    "    'total': {'ngal_per_sq_arcmin': 80}, \n",
    "    # 'xray': {'exposure_time': 10_000},\n",
    "    # 'nclusters': 12\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "csst_noise_params = {**default_noise_params, **csst_params}\n",
    "noisy_images_csst = add_noise_to_images(\n",
    "    all_images,  \n",
    "    all_data_params,  \n",
    "    channels,  \n",
    "    noise_parameters=csst_noise_params  \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open('noisy_csst_images.pkl', 'wb') as f:\n",
    "    pickle.dump(noisy_images_csst, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('noisy_csst_images.pkl', 'rb') as f:\n",
    "    noisy_csst_loaded = pickle.load(f)\n",
    "\n",
    "# check data\n",
    "print(\"csst noise data shape:\", noisy_csst_loaded.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pulsar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
